---
title: "Use the Armadillo"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using Armadillo to perform analysis with DataSHIELD}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



## Usage
When you start to use Armadillo as a backend for DataSHIELD you can use the `DSMolgenisArmadillo` package for research purposes.
There is a default workflow in DataSHIELD to do analysis. There are several steps that you need to take.

- [Install](#install)
- [Authenticate](#authenticate)
- [Assign data](#assign-data)
- [Transform data](#transform-data)
- [Performing analysis](#performing-analysis)
- [Workspaces](#workspaces)

### Install
The DataSHIELD Armadillo package is available on the MOLGENIS CRAN (https://registry.molgenis.org/repository/R). You can install it by executing the following code-block:


```r
install.packages("DSI")
install.packages("DSMolgenisArmadillo", repos = "https://registry.molgenis.org/repository/R", dependencies = TRUE)
```

Make sure you install the DataSHIELD client (`dsBaseClient`) to perform the actual analysis. This needs to be a client which is version 6.0 or higher.


```r
# install the DataSHIELD client
install.packages("dsBase", repos = c("http://cran.datashield.org", "http://cran.us.r-project.org"), dependencies = TRUE)
#> Warning in install.packages :
#>   unable to access index for repository http://cran.datashield.org/bin/macosx/el-capitan/contrib/3.6:
#>   cannot open URL 'http://cran.datashield.org/bin/macosx/el-capitan/contrib/3.6/PACKAGES'
```

**Experimental versions**

If you are interested in using exeperimental versions you can use our own CRAN repository:


```r
# install experimental Armadillo client
install.packages("DSMolgenisArmadillo", repos = "https://registry.molgenis.org/repository/r-hosted-snapshots")
```

Load the necessary packages.


```r
library(dsBaseClient)
library(DSMolgenisArmadillo)
```

### Authenticate
The login procedure consists of building a login dataframe and performing the login on the Armadillo server. The important part is to specify the driver. This should be `ArmadilloDriver`. 

We support authentication 2 flows. 
- as normal user (using oauth on the central authentication server)
- as superuser (using basic authentication, username and password based)

We are currently only using the oauth flow in production environments.
- Authenticate using the authentication server
- Authenticate using the superuser credentials


```r
# method 1: using oauth on the central server
# specify server url
armadillo_url <- "http://localhost:8080"

# get token from central authentication server
token <- armadillo.get_token(armadillo_url)
#> [1] "We're opening a browser so you can log in with code HW852S"
token
#> [1] "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IlcwbmltejhpYU9DLW16OXNaTVRiVzRfbFdMMCJ9.eyJhdWQiOiJiMzk2MjMzYi1jZGIyLTQ0OWUtYWM1Yy1hMGQyOGIzOGY3OTEiLCJleHAiOjE1OTg2MjQ3NTIsImlhdCI6MTU5ODYyMTE1MiwiaXNzIjoiaHR0cHM6Ly9hdXRoLm1vbGdlbmlzLm9yZyIsInN1YiI6IjliY2E3MzJjLThjMjEtNDNkMi1iNTU1LTI3YWZiZjgyZTJmMyIsImF1dGhlbnRpY2F0aW9uVHlwZSI6IlBBU1NXT1JEIiwiZW1haWwiOiJzLmhhYWttYUB1bWNnLm5sIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF0X2hhc2giOiJkelA5ZWhPX0N6RnB3d01tcTV5N2VnIiwiYXBwbGljYXRpb25JZCI6ImIzOTYyMzNiLWNkYjItNDQ5ZS1hYzVjLWEwZDI4YjM4Zjc5MSIsInJvbGVzIjpbIlNVIl0sInBvbGljeSI6InJlYWR3cml0ZSJ9.qRZ6chusMzM_2HeU2my65iqBa_9Iy6Dt9KdxTAuMx5GaCk3I4xetfYo70wJwVlHTrYQTY2vBCP1e8GC9JCXb_njAHDK-7yOsOTyXh_r9WbOWSWqPXDqbByDfQ_gVBCKRZO5wlPd2wK22nMKqCIYoTY3JB8K4Kz_TE3jhTyFBSH268fFvi8b2m_e8j3ClzCdg6XeNWHBG-AATQX3k9c8yi3zBKotFfYkBykP7dYdFWmkYlO99to7M5CI7N4tLD-yhq-5PXa_309QW5YevMXkmIOEXr8azJa4fR6LFKLp9f3L1DzNiJx5t4wMLUHEifot_M3t55oEkrBQG_R5j7le7Mw"
# build the login dataframe
builder <- DSI::newDSLoginBuilder()
builder$append(server = "armadillo",
               url = armadillo_url,
               user = "",
               password = "",
               token = token,
               table = "gecko/2_1-core-1_0/nonrep",
               driver = "ArmadilloDriver")

# create loginframe
logindata <- builder$build()
logindata
#>      server                   url                     table resource          driver user password
#> 1 armadillo http://localhost:8080 gecko/2_1-core-1_0/nonrep          ArmadilloDriver              
#>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  token
#> 1 eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IlcwbmltejhpYU9DLW16OXNaTVRiVzRfbFdMMCJ9.eyJhdWQiOiJiMzk2MjMzYi1jZGIyLTQ0OWUtYWM1Yy1hMGQyOGIzOGY3OTEiLCJleHAiOjE1OTg2MjQ3NTIsImlhdCI6MTU5ODYyMTE1MiwiaXNzIjoiaHR0cHM6Ly9hdXRoLm1vbGdlbmlzLm9yZyIsInN1YiI6IjliY2E3MzJjLThjMjEtNDNkMi1iNTU1LTI3YWZiZjgyZTJmMyIsImF1dGhlbnRpY2F0aW9uVHlwZSI6IlBBU1NXT1JEIiwiZW1haWwiOiJzLmhhYWttYUB1bWNnLm5sIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF0X2hhc2giOiJkelA5ZWhPX0N6RnB3d01tcTV5N2VnIiwiYXBwbGljYXRpb25JZCI6ImIzOTYyMzNiLWNkYjItNDQ5ZS1hYzVjLWEwZDI4YjM4Zjc5MSIsInJvbGVzIjpbIlNVIl0sInBvbGljeSI6InJlYWR3cml0ZSJ9.qRZ6chusMzM_2HeU2my65iqBa_9Iy6Dt9KdxTAuMx5GaCk3I4xetfYo70wJwVlHTrYQTY2vBCP1e8GC9JCXb_njAHDK-7yOsOTyXh_r9WbOWSWqPXDqbByDfQ_gVBCKRZO5wlPd2wK22nMKqCIYoTY3JB8K4Kz_TE3jhTyFBSH268fFvi8b2m_e8j3ClzCdg6XeNWHBG-AATQX3k9c8yi3zBKotFfYkBykP7dYdFWmkYlO99to7M5CI7N4tLD-yhq-5PXa_309QW5YevMXkmIOEXr8azJa4fR6LFKLp9f3L1DzNiJx5t4wMLUHEifot_M3t55oEkrBQG_R5j7le7Mw
#>   options
#> 1

datashield.logout(conns)

# login into server
conns <- datashield.login(logins = logindata, assign = FALSE)
```

The superuser has a simple username and password which you can fill in in the login dataframe.

### Assign data
To work with DataSHIELD you need to be able to query data. You can do this by assigning data in the Armadillo service.


```r
# assign data in the Armadillo service
datashield.assign.table(conns = conns,
                        table = "gecko/2_1-core-1_0/nonrep",
                        symbol = "D",
                        variables = c("recruit_age", "child_id"))
```

#### Symbol assignment
For each of the tables assigned in the Aramdillo a symbol is created in each of the servers. 
You can remove the symbol from the workspace on the server by executing the following code:


```r
# list the current symbols
datashield.symbols(conns)
#> $armadillo
#> [1] "D"
# remove the symbol
datashield.rm(conns = conns, "D")
# list the current symbols without the deleted one
datashield.symbols(conns)
#> $armadillo
#> character(0)
```

#### Assign data using expressions
You can assign values from tables to symbols, but you can use hardcoded expressions as well.


```r
# assign random data to 'K'
datashield.assign.expr(conns = conns, symbol = "K", "c(10,50,100)")
```


```r
# calculate the mean of 'K' to see that the assignment has worked
ds.mean("K", datasources = conns)
#> $Mean.by.Study
#>           EstimatedMean Nmissing Nvalid Ntotal
#> armadillo      53.33333        0      3      3
#> 
#> $Nstudies
#> [1] 1
#> 
#> $ValidityMessage
#>           ValidityMessage 
#> armadillo "VALID ANALYSIS"
```

#### Assign data from tables
When you have assigned symbols in R, you check which tables (`data.frame`'s) are available on the Armadillo.


```r
# assign the data again
datashield.assign.table(conns = conns, 
                        table = "gecko/2_1-core-1_0/nonrep", 
                        symbol = "core_nonrep")
```


```r
# check the columns in the non-repeated data
ds.colnames("core_nonrep", datasources = conns)
#> $armadillo
#>   [1] "row_id"              "child_id"            "mother_id"           "cohort_id"           "preg_no"            
#>   [6] "child_no"            "coh_country"         "recruit_age"         "cob_m"               "ethn1_m"            
#>  [11] "ethn2_m"             "ethn3_m"             "agebirth_m_y"        "agebirth_m_d"        "death_m"            
#>  [16] "death_m_age"         "prepreg_weight"      "prepreg_weight_mes"  "prepreg_weight_ga"   "latepreg_weight"    
#>  [21] "latepreg_weight_mes" "latepreg_weight_ga"  "preg_gain"           "preg_gain_mes"       "height_m"           
#>  [26] "height_mes_m"        "prepreg_dia"         "preg_dia"            "preg_thyroid"        "preg_fever"         
#>  [31] "preeclam"            "preg_ht"             "asthma_m"            "prepreg_psych"       "preg_psych"         
#>  [36] "ppd"                 "prepreg_smk"         "prepreg_cig"         "preg_smk"            "preg_cig"           
#>  [41] "prepreg_alc"         "prepreg_alc_unit"    "preg_alc"            "preg_alc_unit"       "folic_prepreg"      
#>  [46] "folic_preg12"        "folic_post12"        "parity_m"            "preg_plan"           "mar"                
#>  [51] "ivf"                 "outcome"             "mode_delivery"       "plac_abrup"          "cob_p"              
#>  [56] "cob_p_fath"          "ethn1_p"             "ethn2_p"             "ethn3_p"             "ethn_p_fath"        
#>  [61] "agebirth_p_y"        "agebirth_p_d"        "agebirth_p_fath"     "death_p"             "death_p_age"        
#>  [66] "death_p_fath"        "weight_f1"           "weight_mes_f1"       "weight_f1_fath"      "height_f1"          
#>  [71] "height_mes_f1"       "height_f1_fath"      "dia_bf"              "asthma_bf"           "psych_bf"           
#>  [76] "smk_p"               "smk_cig_p"           "smk_fath"            "birth_month"         "birth_year"         
#>  [81] "apgar"               "neo_unit"            "sex"                 "plurality"           "ga_lmp"             
#>  [86] "ga_us"               "ga_mr"               "ga_bj"               "birth_weight"        "birth_length"       
#>  [91] "birth_head_circum"   "weight_who_ga"       "plac_weight"         "con_anomalies"       "major_con_anomalies"
#>  [96] "cer_palsy"           "sibling_pos"         "death_child"         "death_child_age"     "breastfed_excl"     
#> [101] "breastfed_any"       "breastfed_ever"      "solid_food"          "childcare_intro"     "cats_preg"          
#> [106] "dogs_preg"           "cats_quant_preg"     "dogs_quant_preg"
```


### Subsetting data
Before you are working with the data you can subset to a specific range of variables you want to use in the set.


```r
# assign the repeated data to reshape
datashield.assign.table(conns = conns,
                        table = "gecko/2_1-core-1_0/yearlyrep",
                        symbol = "core_yearlyrep")

# check dimensions of repeatead measures
ds.dim("core_yearlyrep", datasources = conns)
#> $`dimensions of core_yearlyrep in armadillo`
#> [1] 19000    34
#> 
#> $`dimensions of core_yearlyrep in combined studies`
#> [1] 19000    34

# subset the data to the first 2 years
ds.dataFrameSubset(df.name = 'core_yearlyrep', newobj = 'core_yearlyrep_1_3', V1.name = "core_yearlyrep$age_years", V2.name = "2", Boolean.operator  = '<=') 
#> $is.object.created
#> [1] "A data object <core_yearlyrep_1_3> has been created in all specified data sources"
#> 
#> $validity.check
#> [1] "<core_yearlyrep_1_3> appears valid in all sources"

# check the columns
ds.colnames("core_yearlyrep_1_3", datasources = conns)
#> $armadillo
#>  [1] "row_id"            "child_id"          "age_years"         "cohab_"            "occup_m_"         
#>  [6] "occupcode_m_"      "edu_m_"            "occup_f1_"         "occup_f1_fath"     "occup_f2_"        
#> [11] "occup_f2_fath"     "occupcode_f1_"     "occupcode_f1_fath" "occupcode_f2_"     "occupcode_f2_fath"
#> [16] "edu_f1_"           "edu_f1_fath"       "edu_f2_"           "edu_f2_fath"       "childcare_"       
#> [21] "childcarerel_"     "childcareprof_"    "childcarecentre_"  "smk_exp"           "pets_"            
#> [26] "cats_"             "cats_quant_"       "dogs_"             "dogs_quant_"       "mental_exp"       
#> [31] "hhincome_"         "fam_splitup"       "famsize_child"     "famsize_adult"

# check dimensions again
ds.dim("core_yearlyrep_1_3", datasources = conns)
#> $`dimensions of core_yearlyrep_1_3 in armadillo`
#> [1] 3000   34
#> 
#> $`dimensions of core_yearlyrep_1_3 in combined studies`
#> [1] 3000   34
```


```r
# strip the redundant columns
ds.dataFrame(x = c("core_yearlyrep_1_3$child_id", "core_yearlyrep_1_3$age_years", "core_yearlyrep_1_3$dogs_",  "core_yearlyrep_1_3$cats_",  "core_yearlyrep_1_3$pets_"),
             completeCases = TRUE,
             newobj = "core_yearlyrep_1_3_stripped",
             datasources = conns)
#> $is.object.created
#> [1] "A data object <core_yearlyrep_1_3_stripped> has been created in all specified data sources"
#> 
#> $validity.check
#> [1] "<core_yearlyrep_1_3_stripped> appears valid in all sources"
```

### Transform data
In general you need 2 methods to work with data that is stored in long format, the `reshape` and `merge` functions in DataSHIELD. You can reshape data with the Armadillo to transform data from [wide-format to long-format](https://www.theanalysisfactor.com/wide-and-long-data/) and vice versa. 

You can do this using the `ds.reshape` function:


```r
# reshape the data for the wide-format variables (yearlyrep)
ds.reShape(data.name='core_yearlyrep_1_3_stripped',
           timevar.name = 'age_years',
           idvar.name = 'child_id',
           v.names=c("pets_", "cats_", "dogs_"),
           direction = 'wide',
           newobj = "core_yearlyrep_1_3_wide",
           datasources = conns
)
#> $is.object.created
#> [1] "A data object <core_yearlyrep_1_3_wide> has been created in all specified data sources"
#> 
#> $validity.check
#> [1] "<core_yearlyrep_1_3_wide> appears valid in all sources"
```


```r
# show the reshaped columns of the new data frame
ds.colnames("core_yearlyrep_1_3_wide", datasources = conns)
#> $armadillo
#>  [1] "child_id" "pets_.0"  "cats_.0"  "dogs_.0"  "pets_.1"  "cats_.1"  "dogs_.1"  "pets_.2"  "cats_.2"  "dogs_.2"
```

When you reshaped and subsetted the data you often need to merge your dataframe with others to get your analysis dataframe. You can do this using the `ds.merge` function:


```r
# merge non-repeated table with wide-format repeated table
# make sure the disclosure measure regarding stringshort is set to '100'
ds.merge(x.name = 'core_nonrep',
         y.name = 'core_yearlyrep_1_3_wide',
         by.x.names = 'child_id',
         by.y.names = 'child_id',
         newobj = 'analysis_df',
         datasources = conns
)
#> $is.object.created
#> [1] "A data object <analysis_df> has been created in all specified data sources"
#> 
#> $validity.check
#> [1] "<analysis_df> appears valid in all sources"
```


```r
ds.colnames("analysis_df", datasources = conns)
#> $armadillo
#>   [1] "child_id"            "row_id"              "mother_id"           "cohort_id"           "preg_no"            
#>   [6] "child_no"            "coh_country"         "recruit_age"         "cob_m"               "ethn1_m"            
#>  [11] "ethn2_m"             "ethn3_m"             "agebirth_m_y"        "agebirth_m_d"        "death_m"            
#>  [16] "death_m_age"         "prepreg_weight"      "prepreg_weight_mes"  "prepreg_weight_ga"   "latepreg_weight"    
#>  [21] "latepreg_weight_mes" "latepreg_weight_ga"  "preg_gain"           "preg_gain_mes"       "height_m"           
#>  [26] "height_mes_m"        "prepreg_dia"         "preg_dia"            "preg_thyroid"        "preg_fever"         
#>  [31] "preeclam"            "preg_ht"             "asthma_m"            "prepreg_psych"       "preg_psych"         
#>  [36] "ppd"                 "prepreg_smk"         "prepreg_cig"         "preg_smk"            "preg_cig"           
#>  [41] "prepreg_alc"         "prepreg_alc_unit"    "preg_alc"            "preg_alc_unit"       "folic_prepreg"      
#>  [46] "folic_preg12"        "folic_post12"        "parity_m"            "preg_plan"           "mar"                
#>  [51] "ivf"                 "outcome"             "mode_delivery"       "plac_abrup"          "cob_p"              
#>  [56] "cob_p_fath"          "ethn1_p"             "ethn2_p"             "ethn3_p"             "ethn_p_fath"        
#>  [61] "agebirth_p_y"        "agebirth_p_d"        "agebirth_p_fath"     "death_p"             "death_p_age"        
#>  [66] "death_p_fath"        "weight_f1"           "weight_mes_f1"       "weight_f1_fath"      "height_f1"          
#>  [71] "height_mes_f1"       "height_f1_fath"      "dia_bf"              "asthma_bf"           "psych_bf"           
#>  [76] "smk_p"               "smk_cig_p"           "smk_fath"            "birth_month"         "birth_year"         
#>  [81] "apgar"               "neo_unit"            "sex"                 "plurality"           "ga_lmp"             
#>  [86] "ga_us"               "ga_mr"               "ga_bj"               "birth_weight"        "birth_length"       
#>  [91] "birth_head_circum"   "weight_who_ga"       "plac_weight"         "con_anomalies"       "major_con_anomalies"
#>  [96] "cer_palsy"           "sibling_pos"         "death_child"         "death_child_age"     "breastfed_excl"     
#> [101] "breastfed_any"       "breastfed_ever"      "solid_food"          "childcare_intro"     "cats_preg"          
#> [106] "dogs_preg"           "cats_quant_preg"     "dogs_quant_preg"     "pets_.0"             "cats_.0"            
#> [111] "dogs_.0"             "pets_.1"             "cats_.1"             "dogs_.1"             "pets_.2"            
#> [116] "cats_.2"             "dogs_.2"
```

### Performing analysis
There are a variety of analysis you can perform in DataSHIELD. You can perform basic merthods such as summary statistics and more advanced methods susch as GLM.

#### Simple statistical methods
You execute a summary on the a variable within you analysis frame. It will return summary statistics.


```r
ds.summary("analysis_df$pets_.1", datasources = conns)
#> $armadillo
#> $armadillo$class
#> [1] "numeric"
#> 
#> $armadillo$length
#> [1] 1000
#> 
#> $armadillo$`quantiles & mean`
#>      5%     10%     25%     50%     75%     90%     95%    Mean 
#>   8.000  15.000  32.750  61.000  90.000 108.000 113.000  60.954
```

#### Advanced statistical methods
When you finished the analysis dataframe, you can perform the actual analysis. You can use a wide variety of functions. The example below is showing the `glm`. After that you can create a 


```r
datashield.assign.table(conns = conns,
                        table = "gecko/1_1-outcome-1_0/nonrep",
                        symbol = "outcome_nonrep")

armadillo_glm <- ds.glm(formula = 'asthma_ever_CHICOS~pets_preg',
        data = 'outcome_nonrep',
        family = 'binomial',
        datasources = conns)
```

Do the meta analysis and install prerequisites.


```r
install.packages("metafor")
#> Error in install.packages : Updating loaded packages
```


```r
yi <- c(armadillo_glm$coefficients["pets_preg", "Estimate"])
sei <- c(armadillo_glm$coefficients["pets_preg", "Std. Error"])

res <- metafor::rma(yi, sei = sei)
res
#> 
#> Fixed-Effects Model (k = 1)
#> 
#> I^2 (total heterogeneity / total variability):   0.00%
#> H^2 (total variability / sampling variability):  1.00
#> 
#> Test for Heterogeneity:
#> Q(df = 0) = 0.0000, p-val = 1.0000
#> 
#> Model Results:
#> 
#> estimate      se     zval    pval    ci.lb   ci.ub 
#>  -0.1310  0.1267  -1.0343  0.3010  -0.3793  0.1173    
#> 
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
metafor::forest(res, xlab = "OR", transf = exp, refline = 1, slab = c("armadillo_glm"))
```

<img src="DSMolgenisArmadillo-meta-analysis-1.png" title="plot of chunk meta-analysis" alt="plot of chunk meta-analysis" width="100%" />

#### Creating figures
You can directly create figures with the DataSHIELD methods. For example:


```r
# create histogram
ds.histogram(x = "core_nonrep$coh_country", datasources = conns)
```

<img src="DSMolgenisArmadillo-create-a-histogram-1.png" title="plot of chunk create-a-histogram" alt="plot of chunk create-a-histogram" width="100%" />

```
#> $breaks
#>  [1]  34.40373 115.17616 195.94859 276.72101 357.49344 438.26587 519.03830 599.81072 680.58315 761.35558 842.12800
#> 
#> $counts
#>  [1] 103 103  91 102 108 103 103  98 117  72
#> 
#> $density
#>  [1] 0.0012751876 0.0012751876 0.0011266221 0.0012628072 0.0013370899 0.0012751876 0.0012751876 0.0012132853 0.0014485141
#> [10] 0.0008913933
#> 
#> $mids
#>  [1]  74.78995 155.56237 236.33480 317.10723 397.87965 478.65208 559.42451 640.19694 720.96936 801.74179
#> 
#> $xname
#> [1] "xvect"
#> 
#> $equidist
#> [1] TRUE
#> 
#> attr(,"class")
#> [1] "histogram"
```



```r
# create a heatmap
ds.heatmapPlot(x = "analysis_df$pets_.1", y = "analysis_df$dogs_.1", datasources = conns)
```

<img src="DSMolgenisArmadillo-create-a-heatmap-1.png" title="plot of chunk create-a-heatmap" alt="plot of chunk create-a-heatmap" width="100%" />


```r
# logout
datashield.logout(conns)
```

### Workspaces
To store the assigned data in the Armadillo service, you can use workspaces to make sure a certain state of the data is maintained on the service.

Saving the workspaces can be done during `datashield.logout` or at runtime.


```r
conns <- datashield.login(login = logindata)

datashield.assign.table(conns = conns,
                        table = "gecko/2_1-core-1_0/nonrep",
                        symbol = "J",
                        variables = c("recruit_age", "child_id"))

datashield.logout(conns, save = "my-workspace")

conns <- datashield.login(logins = logindata, 
                          assign = FALSE, 
                          restore = "my-workspace")

datashield.symbols(conns)
#> $armadillo
#> [1] "J"
datashield.workspace_save(conns, "my-workspace-version-2")
```

You can overwrite workspaces using the same name again when saving the workspace.


```r
datashield.logout(conns)
conns <- datashield.login(logins = logindata)

datashield.assign.table(conns = conns, 
                        table = "gecko/2_1-core-1_0/nonrep", 
                        symbol = "H")

datashield.workspace_save(conns, "my-workspace-overwritten")
datashield.workspace_save(conns, "my-workspace-overwritten")
```

You can list the workspaces as well.


```r
datashield.workspaces(conns$armadillo)
#>             lastAccessDate                               name   size                               ETag user
#> 1 2020-08-28T13:26:05.370Z armadillo:my-workspace-overwritten 172072 "79ea8e26a41a0f43716040c5f09466c0"     
#> 2 2020-08-28T13:26:03.861Z   armadillo:my-workspace-version-2   3610 "7de51b96e6d15e9ab13b9ef52fe3547f"     
#> 3 2020-08-28T13:26:03.292Z             armadillo:my-workspace   3610 "7de51b96e6d15e9ab13b9ef52fe3547f"
```

Remove workspaces.


```r
datashield.workspace_rm(conns, "my-workspace-overwritten")
datashield.workspaces(conns)
#>      server name..armadillo.my.workspace.version.2. name..armadillo.my.workspace. user
#> 1 armadillo        armadillo:my-workspace-version-2        armadillo:my-workspace     
#> 2 armadillo        armadillo:my-workspace-version-2        armadillo:my-workspace     
#>   lastAccessDate..2020.08.28T13.26.03.861Z. lastAccessDate..2020.08.28T13.26.03.292Z. size.3610L size.3610L.1
#> 1                  2020-08-28T13:26:03.861Z                  2020-08-28T13:26:03.292Z       3610         3610
#> 2                  2020-08-28T13:26:03.861Z                  2020-08-28T13:26:03.292Z       3610         3610
```
